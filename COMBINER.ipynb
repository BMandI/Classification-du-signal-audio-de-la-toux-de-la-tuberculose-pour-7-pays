{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8994aece-7c35-471c-8a3b-135d7551bd43",
   "metadata": {},
   "source": [
    "# ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "494a570c-0709-487e-ab31-7a57c8376471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les fichiers ont été combinés avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Liste des pays\n",
    "pays = ['VN', 'PH', 'SA', 'IN', 'UG', 'TZ', 'MG']\n",
    "# Chemin vers le dossier Metrics\n",
    "dossier_metrics = 'Metrics'\n",
    "\n",
    "# Initialiser une liste pour stocker les DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Parcourir chaque pays\n",
    "for pays in pays:\n",
    "    # Chemin vers les deux fichiers possibles\n",
    "    chemin_fichier_1 = os.path.join(dossier_metrics, pays, 'ML', 'best_Fold_Model.csv')\n",
    "    chemin_fichier_2 = os.path.join(dossier_metrics, pays, 'ML', 'Best_Fold_Model.csv')\n",
    "\n",
    "    # Vérifier si le fichier existe et le lire\n",
    "    if os.path.exists(chemin_fichier_1):\n",
    "        df = pd.read_csv(chemin_fichier_1)\n",
    "        df['Country'] = pays  # Ajouter une colonne pour le pays\n",
    "        dataframes.append(df)\n",
    "    elif os.path.exists(chemin_fichier_2):\n",
    "        df = pd.read_csv(chemin_fichier_2)\n",
    "        df['Country'] = pays\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Combiner tous les DataFrames en un seul\n",
    "if dataframes:\n",
    "    resultat_combined = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Réorganiser les colonnes comme demandé\n",
    "    colonnes_d_interet = ['Country', 'Best Model', 'Test Accuracy', 'Test Sensitivity', 'Test Specificity', 'Test F1 Score', 'Test AUC']\n",
    "\n",
    "    # Filtrer les colonnes existantes\n",
    "    colonnes_existantes = [col for col in colonnes_d_interet if col in resultat_combined.columns]\n",
    "    resultat_combined = resultat_combined[colonnes_existantes]\n",
    "\n",
    "    # Arrondir les métriques souhaitées (ajuste les colonnes selon tes besoins)\n",
    "    métriques = ['Test Accuracy', 'Test Sensitivity', 'Test Specificity', 'Test F1 Score', 'Test AUC']\n",
    "    resultat_combined[métriques] = resultat_combined[métriques].round(2)  # Arrondir à 2 décimales\n",
    "\n",
    "    # Enregistrer le résultat combiné dans un nouveau fichier CSV\n",
    "    resultat_combined.to_csv('Metrics/Combined_ML.csv', index=False)\n",
    "\n",
    "    print(\"Les fichiers ont été combinés avec succès.\")\n",
    "else:\n",
    "    print(\"Aucun fichier trouvé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b815c88d-6e46-4001-aa2b-1d7db265f539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Best Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Sensitivity</th>\n",
       "      <th>Test Specificity</th>\n",
       "      <th>Test F1 Score</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VN</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PH</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SA</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IN</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UG</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TZ</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MG</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country              Best Model  Test Accuracy  Test Sensitivity  \\\n",
       "0      VN    KNeighborsClassifier           0.36              0.08   \n",
       "1      PH  RandomForestClassifier           0.90              0.00   \n",
       "2      SA      LogisticRegression           0.46              0.50   \n",
       "3      IN      LogisticRegression           0.75              0.00   \n",
       "4      UG  RandomForestClassifier           0.66              0.06   \n",
       "5      TZ                     SVC           0.28              0.33   \n",
       "6      MG      LogisticRegression           0.59              0.53   \n",
       "\n",
       "   Test Specificity  Test F1 Score  Test AUC  \n",
       "0              0.55           0.09      0.34  \n",
       "1              1.00           0.00      0.73  \n",
       "2              0.45           0.29      0.45  \n",
       "3              0.86           0.00      0.52  \n",
       "4              0.97           0.11      0.46  \n",
       "5              0.27           0.13      0.87  \n",
       "6              0.65           0.55      0.64  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chemin vers le fichier combiné\n",
    "chemin_fichier_combined = 'Metrics/Combined_ML.csv'\n",
    "\n",
    "# Lire le fichier CSV\n",
    "df_combined = pd.read_csv(chemin_fichier_combined)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ceca6-8d7e-443b-82e5-9850c0e80122",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7fac6b53-843c-4843-96e8-4e8420794b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les fichiers ont été combinés avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Liste des pays\n",
    "pays = ['VN', 'PH', 'SA', 'IN', 'UG', 'TZ', 'MG']\n",
    "# Chemin vers le dossier Metrics\n",
    "dossier_metrics = 'Metrics'\n",
    "\n",
    "# Initialiser une liste pour stocker les DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Parcourir chaque pays\n",
    "for pays in pays:\n",
    "    # Chemin vers le dossier CNN\n",
    "    dossier_cnn = os.path.join(dossier_metrics, pays, 'CNN')\n",
    "\n",
    "    # Lister tous les fichiers dans le dossier\n",
    "    for fichier in os.listdir(dossier_cnn):\n",
    "        # Vérifier si le fichier commence par \"Predictions\"\n",
    "        if fichier.startswith('Predictions'):\n",
    "            chemin_fichier = os.path.join(dossier_cnn, fichier)\n",
    "            df = pd.read_csv(chemin_fichier)\n",
    "\n",
    "            # Vérifier que les colonnes attendues sont présentes\n",
    "            if 'Metric' in df.columns and 'Value' in df.columns:\n",
    "                # Ajouter une colonne pour le pays\n",
    "                df['Country'] = pays\n",
    "                \n",
    "                # Réorganiser le DataFrame pour correspondre à la structure désirée\n",
    "                df = df.rename(columns={'Metric': 'Metric', 'Value': 'Value'})\n",
    "                df['Model'] = df['Metric'].apply(lambda x: 'CNN' if x == 'Model' else None)\n",
    "\n",
    "                # Remplacer les NaN par des valeurs appropriées\n",
    "                df['Model'] = df['Model'].ffill()\n",
    "\n",
    "                # Filtrer pour garder uniquement les lignes avec des métriques\n",
    "                df = df[df['Metric'] != 'Model']\n",
    "                \n",
    "                # Ajouter le DataFrame à la liste\n",
    "                dataframes.append(df)\n",
    "\n",
    "# Combiner tous les DataFrames en un seul\n",
    "if dataframes:\n",
    "    resultat_combined = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Réorganiser les colonnes comme demandé\n",
    "    colonnes_d_interet = ['Country', 'Model', 'Metric', 'Value']\n",
    "\n",
    "    # Filtrer les colonnes existantes\n",
    "    colonnes_existantes = [col for col in colonnes_d_interet if col in resultat_combined.columns]\n",
    "    resultat_combined = resultat_combined[colonnes_existantes]\n",
    "\n",
    "    # Convertir la colonne 'Value' en numérique\n",
    "    resultat_combined['Value'] = pd.to_numeric(resultat_combined['Value'], errors='coerce')\n",
    "\n",
    "    # Arrondir les valeurs à 2 décimales\n",
    "    resultat_combined['Value'] = resultat_combined['Value'].round(2)\n",
    "\n",
    "    # Enregistrer le résultat combiné dans un nouveau fichier CSV\n",
    "    resultat_combined.to_csv('Metrics/Combined_CNN.csv', index=False)\n",
    "\n",
    "    print(\"Les fichiers ont été combinés avec succès.\")\n",
    "else:\n",
    "    print(\"Aucun fichier trouvé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a40a7f0d-8694-4d6a-ab59-2e6e38ac68c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Model</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country Model       Metric  Value\n",
       "0       VN   CNN     Accuracy   0.70\n",
       "1       VN   CNN       Recall   0.31\n",
       "2       VN   CNN     F1 Score   0.44\n",
       "3       VN   CNN  Specificity   0.95\n",
       "4       VN   CNN      AUC-ROC   0.72\n",
       "5       PH   CNN     Accuracy   0.74\n",
       "6       PH   CNN       Recall   0.50\n",
       "7       PH   CNN     F1 Score   0.29\n",
       "8       PH   CNN  Specificity   0.77\n",
       "9       PH   CNN      AUC-ROC   0.71\n",
       "10      SA   CNN     Accuracy   0.61\n",
       "11      SA   CNN       Recall   0.17\n",
       "12      SA   CNN     F1 Score   0.15\n",
       "13      SA   CNN  Specificity   0.73\n",
       "14      SA   CNN      AUC-ROC   0.28\n",
       "15      IN   CNN     Accuracy   0.50\n",
       "16      IN   CNN       Recall   1.00\n",
       "17      IN   CNN     F1 Score   0.33\n",
       "18      IN   CNN  Specificity   0.43\n",
       "19      IN   CNN      AUC-ROC   0.78\n",
       "20      UG   CNN     Accuracy   0.32\n",
       "21      UG   CNN       Recall   0.56\n",
       "22      UG   CNN     F1 Score   0.36\n",
       "23      UG   CNN  Specificity   0.19\n",
       "24      UG   CNN      AUC-ROC   0.39\n",
       "25      TZ   CNN     Accuracy   0.61\n",
       "26      TZ   CNN       Recall   0.67\n",
       "27      TZ   CNN     F1 Score   0.36\n",
       "28      TZ   CNN  Specificity   0.60\n",
       "29      TZ   CNN      AUC-ROC   0.56\n",
       "30      MG   CNN     Accuracy   0.59\n",
       "31      MG   CNN       Recall   0.47\n",
       "32      MG   CNN     F1 Score   0.52\n",
       "33      MG   CNN  Specificity   0.71\n",
       "34      MG   CNN      AUC-ROC   0.65"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chemin vers le fichier combiné\n",
    "chemin_fichier_combined = 'Metrics/Combined_CNN.csv'\n",
    "\n",
    "# Lire le fichier CSV\n",
    "df_combined = pd.read_csv(chemin_fichier_combined)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "59938790-bb47-49ab-8321-4efc5bd8f85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les fichiers ont été combinés avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Liste des pays\n",
    "pays = ['VN', 'PH', 'SA', 'IN', 'UG', 'TZ', 'MG']\n",
    "# Chemin vers le dossier Metrics\n",
    "dossier_metrics = 'Metrics'\n",
    "\n",
    "# Initialiser une liste pour stocker les DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Parcourir chaque pays\n",
    "for pays in pays:\n",
    "    # Chemin vers le dossier CNN\n",
    "    dossier_cnn = os.path.join(dossier_metrics, pays, 'CNN')\n",
    "\n",
    "    # Lister tous les fichiers dans le dossier\n",
    "    for fichier in os.listdir(dossier_cnn):\n",
    "        # Vérifier si le fichier commence par \"Predictions\"\n",
    "        if fichier.startswith('Predictions'):\n",
    "            chemin_fichier = os.path.join(dossier_cnn, fichier)\n",
    "            df = pd.read_csv(chemin_fichier)\n",
    "\n",
    "            # Vérifier que les colonnes attendues sont présentes\n",
    "            if 'Metric' in df.columns and 'Value' in df.columns:\n",
    "                # Ajouter une colonne pour le pays\n",
    "                df['Country'] = pays\n",
    "                \n",
    "                # Réorganiser le DataFrame pour correspondre à la structure désirée\n",
    "                df = df.rename(columns={'Metric': 'Metric', 'Value': 'Value'})\n",
    "                df['Model'] = df['Metric'].apply(lambda x: 'CNN' if x == 'Model' else None)\n",
    "\n",
    "                # Remplacer les NaN par des valeurs appropriées\n",
    "                df['Model'] = df['Model'].ffill()\n",
    "\n",
    "                # Filtrer pour garder uniquement les lignes avec des métriques\n",
    "                df = df[df['Metric'] != 'Model']\n",
    "                \n",
    "                # Ajouter le DataFrame à la liste\n",
    "                dataframes.append(df)\n",
    "\n",
    "# Combiner tous les DataFrames en un seul\n",
    "if dataframes:\n",
    "    resultat_combined = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Réorganiser les colonnes comme demandé\n",
    "    colonnes_d_interet = ['Country', 'Model', 'Metric', 'Value']\n",
    "\n",
    "    # Filtrer les colonnes existantes\n",
    "    colonnes_existantes = [col for col in colonnes_d_interet if col in resultat_combined.columns]\n",
    "    resultat_combined = resultat_combined[colonnes_existantes]\n",
    "\n",
    "    # Convertir la colonne 'Value' en numérique\n",
    "    resultat_combined['Value'] = pd.to_numeric(resultat_combined['Value'], errors='coerce')\n",
    "\n",
    "    # Arrondir les valeurs à 2 décimales\n",
    "    resultat_combined['Value'] = resultat_combined['Value'].round(2)\n",
    "\n",
    "    # Optionnel : Convertir les valeurs arrondies en chaînes formatées\n",
    "    resultat_combined['Value'] = resultat_combined['Value'].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "    # Enregistrer le résultat combiné dans un nouveau fichier CSV\n",
    "    resultat_combined.to_csv('Metrics/Combined_CNN.csv', index=False)\n",
    "\n",
    "    print(\"Les fichiers ont été combinés avec succès.\")\n",
    "else:\n",
    "    print(\"Aucun fichier trouvé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "26f18939-6cdf-452d-becd-4bc15d8dfdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Model</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Recall</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country Model       Metric  Value\n",
       "0       VN   CNN     Accuracy   0.70\n",
       "1       VN   CNN       Recall   0.31\n",
       "2       VN   CNN     F1 Score   0.44\n",
       "3       VN   CNN  Specificity   0.95\n",
       "4       VN   CNN      AUC-ROC   0.72\n",
       "5       PH   CNN     Accuracy   0.74\n",
       "6       PH   CNN       Recall   0.50\n",
       "7       PH   CNN     F1 Score   0.29\n",
       "8       PH   CNN  Specificity   0.77\n",
       "9       PH   CNN      AUC-ROC   0.71\n",
       "10      SA   CNN     Accuracy   0.61\n",
       "11      SA   CNN       Recall   0.17\n",
       "12      SA   CNN     F1 Score   0.15\n",
       "13      SA   CNN  Specificity   0.73\n",
       "14      SA   CNN      AUC-ROC   0.28\n",
       "15      IN   CNN     Accuracy   0.50\n",
       "16      IN   CNN       Recall   1.00\n",
       "17      IN   CNN     F1 Score   0.33\n",
       "18      IN   CNN  Specificity   0.43\n",
       "19      IN   CNN      AUC-ROC   0.78\n",
       "20      UG   CNN     Accuracy   0.32\n",
       "21      UG   CNN       Recall   0.56\n",
       "22      UG   CNN     F1 Score   0.36\n",
       "23      UG   CNN  Specificity   0.19\n",
       "24      UG   CNN      AUC-ROC   0.39\n",
       "25      TZ   CNN     Accuracy   0.61\n",
       "26      TZ   CNN       Recall   0.67\n",
       "27      TZ   CNN     F1 Score   0.36\n",
       "28      TZ   CNN  Specificity   0.60\n",
       "29      TZ   CNN      AUC-ROC   0.56\n",
       "30      MG   CNN     Accuracy   0.59\n",
       "31      MG   CNN       Recall   0.47\n",
       "32      MG   CNN     F1 Score   0.52\n",
       "33      MG   CNN  Specificity   0.71\n",
       "34      MG   CNN      AUC-ROC   0.65"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chemin vers le fichier combiné\n",
    "chemin_fichier_combined = 'Metrics/Combined_CNN.csv'\n",
    "\n",
    "# Lire le fichier CSV\n",
    "df_combined = pd.read_csv(chemin_fichier_combined)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0b2cd27-0a89-4a12-aa76-ac4a69ab807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les fichiers ont été combinés et les métriques affichées en colonnes avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Liste des pays\n",
    "pays = ['VN', 'PH', 'SA', 'IN', 'UG', 'TZ', 'MG']\n",
    "# Chemin vers le dossier Metrics\n",
    "dossier_metrics = 'Metrics'\n",
    "\n",
    "# Initialiser une liste pour stocker les DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Parcourir chaque pays\n",
    "for pays in pays:\n",
    "    # Chemin vers le dossier CNN\n",
    "    dossier_cnn = os.path.join(dossier_metrics, pays, 'CNN_LSTM')\n",
    "\n",
    "    # Lister tous les fichiers dans le dossier\n",
    "    for fichier in os.listdir(dossier_cnn):\n",
    "        # Vérifier si le fichier commence par \"Predictions\"\n",
    "        if fichier.startswith('Predictions'):\n",
    "            chemin_fichier = os.path.join(dossier_cnn, fichier)\n",
    "            df = pd.read_csv(chemin_fichier)\n",
    "\n",
    "            # Vérifier que les colonnes attendues sont présentes\n",
    "            if 'Metric' in df.columns and 'Value' in df.columns:\n",
    "                # Ajouter une colonne pour le pays\n",
    "                df['Country'] = pays\n",
    "                df['Model'] = 'CNN_LSTM'  # Ajouter le nom du modèle\n",
    "                \n",
    "                # Convertir la colonne Value en numérique\n",
    "                df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
    "\n",
    "                # Arrondir les valeurs à 2 décimales\n",
    "                df['Value'] = df['Value'].round(2)\n",
    "\n",
    "                # Ajouter le DataFrame à la liste\n",
    "                dataframes.append(df)\n",
    "\n",
    "# Combiner tous les DataFrames en un seul\n",
    "if dataframes:\n",
    "    resultat_combined = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Pivot des données pour afficher les métriques en colonnes\n",
    "    resultat_pivot = resultat_combined.pivot_table(index=['Country', 'Model'], columns='Metric', values='Value', aggfunc='first').reset_index()\n",
    "\n",
    "    # Enregistrer le résultat combiné dans un nouveau fichier CSV\n",
    "    resultat_pivot.to_csv('Metrics/Combined_CNN_LSTM.csv', index=False)\n",
    "\n",
    "    print(\"Les fichiers ont été combinés et les métriques affichées en colonnes avec succès.\")\n",
    "else:\n",
    "    print(\"Aucun fichier trouvé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ccb80417-0679-4e38-8c79-78620cf210bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country     Model  AUC-ROC  Accuracy  F1 Score  Recall  Specificity\n",
       "0      IN  CNN_LSTM     0.38      0.88      0.00    0.00         1.00\n",
       "1      MG  CNN_LSTM     0.58      0.53      0.21    0.13         0.88\n",
       "2      PH  CNN_LSTM     0.34      0.87      0.00    0.00         0.97\n",
       "3      SA  CNN_LSTM     0.44      0.71      0.33    0.33         0.82\n",
       "4      TZ  CNN_LSTM     0.40      0.83      0.00    0.00         1.00\n",
       "5      UG  CNN_LSTM     0.53      0.55      0.40    0.44         0.61\n",
       "6      VN  CNN_LSTM     0.61      0.55      0.48    0.54         0.55"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chemin vers le fichier combiné\n",
    "chemin_fichier_combined = 'Metrics/Combined_CNN_LSTM.csv'\n",
    "\n",
    "# Lire le fichier CSV\n",
    "df_combined = pd.read_csv(chemin_fichier_combined)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cb1d64-f305-47e0-9dc9-def7b4f627fe",
   "metadata": {},
   "source": [
    "# RNN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7544a12a-d968-49f3-bece-e7448df6d793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les fichiers ont été combinés et les métriques affichées en colonnes avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Liste des pays\n",
    "pays = ['VN', 'PH', 'SA', 'IN', 'UG', 'TZ', 'MG']\n",
    "# Chemin vers le dossier Metrics\n",
    "dossier_metrics = 'Metrics'\n",
    "\n",
    "# Initialiser une liste pour stocker les DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Parcourir chaque pays\n",
    "for pays in pays:\n",
    "    # Chemin vers le dossier RNN\n",
    "    dossier_cnn = os.path.join(dossier_metrics, pays, 'RNN_LSTM')\n",
    "\n",
    "    # Lister tous les fichiers dans le dossier\n",
    "    for fichier in os.listdir(dossier_cnn):\n",
    "        # Vérifier si le fichier commence par \"Predictions\"\n",
    "        if fichier.startswith('Predictions'):\n",
    "            chemin_fichier = os.path.join(dossier_cnn, fichier)\n",
    "            df = pd.read_csv(chemin_fichier)\n",
    "\n",
    "            # Vérifier que les colonnes attendues sont présentes\n",
    "            if 'Metric' in df.columns and 'Value' in df.columns:\n",
    "                # Ajouter une colonne pour le pays\n",
    "                df['Country'] = pays\n",
    "                df['Model'] = 'RNN_LSTM'  # Ajouter le nom du modèle\n",
    "                \n",
    "                # Convertir la colonne Value en numérique\n",
    "                df['Value'] = pd.to_numeric(df['Value'], errors='coerce')\n",
    "\n",
    "                # Arrondir les valeurs à 2 décimales\n",
    "                df['Value'] = df['Value'].round(2)\n",
    "\n",
    "                # Ajouter le DataFrame à la liste\n",
    "                dataframes.append(df)\n",
    "\n",
    "# Combiner tous les DataFrames en un seul\n",
    "if dataframes:\n",
    "    resultat_combined = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Pivot des données pour afficher les métriques en colonnes\n",
    "    resultat_pivot = resultat_combined.pivot_table(index=['Country', 'Model'], columns='Metric', values='Value', aggfunc='first').reset_index()\n",
    "\n",
    "    # Enregistrer le résultat combiné dans un nouveau fichier CSV\n",
    "    resultat_pivot.to_csv('Metrics/Combined_RNN_LSTM.csv', index=False)\n",
    "\n",
    "    print(\"Les fichiers ont été combinés et les métriques affichées en colonnes avec succès.\")\n",
    "else:\n",
    "    print(\"Aucun fichier trouvé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a006165e-5e44-43f2-8917-7756efc0bfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IN</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MG</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PH</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SA</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TZ</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UG</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VN</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country     Model  AUC-ROC  Accuracy  F1 Score  Recall  Specificity\n",
       "0      IN  RNN_LSTM     0.35      0.75      0.00    0.00         0.86\n",
       "1      MG  RNN_LSTM     0.48      0.50      0.38    0.33         0.65\n",
       "2      PH  RNN_LSTM     0.49      0.28      0.22    1.00         0.20\n",
       "3      SA  RNN_LSTM     0.51      0.64      0.17    0.17         0.77\n",
       "4      TZ  RNN_LSTM     0.38      0.44      0.17    0.33         0.47\n",
       "5      UG  RNN_LSTM     0.45      0.40      0.26    0.31         0.45\n",
       "6      VN  RNN_LSTM     0.72      0.70      0.44    0.31         0.95"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chemin vers le fichier combiné\n",
    "chemin_fichier_combined = 'Metrics/Combined_RNN_LSTM.csv'\n",
    "\n",
    "# Lire le fichier CSV\n",
    "df_combined = pd.read_csv(chemin_fichier_combined)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af9f8c-674e-444e-a17b-e69f27c7fd54",
   "metadata": {},
   "source": [
    "# Combine les 4 fichiers combinés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "41d1e185-8088-4cf4-a637-87b360447abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du fichier : Metrics/Combined_ML.csv\n",
      "Aperçu des données avant traitement :\n",
      "  Country              Best Model  Test Accuracy  Test Sensitivity  \\\n",
      "0      VN    KNeighborsClassifier           0.36              0.08   \n",
      "1      PH  RandomForestClassifier           0.90              0.00   \n",
      "2      SA      LogisticRegression           0.46              0.50   \n",
      "3      IN      LogisticRegression           0.75              0.00   \n",
      "4      UG  RandomForestClassifier           0.66              0.06   \n",
      "\n",
      "   Test Specificity  Test F1 Score  Test AUC  \n",
      "0              0.55           0.09      0.34  \n",
      "1              1.00           0.00      0.73  \n",
      "2              0.45           0.29      0.45  \n",
      "3              0.86           0.00      0.52  \n",
      "4              0.97           0.11      0.46  \n",
      "Traitement du fichier : Metrics/Combined_CNN.csv\n",
      "Aperçu des données avant traitement :\n",
      "  Country Model       Metric  Value\n",
      "0      VN   CNN     Accuracy   0.70\n",
      "1      VN   CNN       Recall   0.31\n",
      "2      VN   CNN     F1 Score   0.44\n",
      "3      VN   CNN  Specificity   0.95\n",
      "4      VN   CNN      AUC-ROC   0.72\n",
      "Traitement du fichier : Metrics/Combined_CNN_LSTM.csv\n",
      "Aperçu des données avant traitement :\n",
      "  Country     Model  AUC-ROC  Accuracy  F1 Score  Recall  Specificity\n",
      "0      IN  CNN_LSTM     0.38      0.88      0.00    0.00         1.00\n",
      "1      MG  CNN_LSTM     0.58      0.53      0.21    0.13         0.88\n",
      "2      PH  CNN_LSTM     0.34      0.87      0.00    0.00         0.97\n",
      "3      SA  CNN_LSTM     0.44      0.71      0.33    0.33         0.82\n",
      "4      TZ  CNN_LSTM     0.40      0.83      0.00    0.00         1.00\n",
      "Traitement du fichier : Metrics/Combined_RNN_LSTM.csv\n",
      "Aperçu des données avant traitement :\n",
      "  Country     Model  AUC-ROC  Accuracy  F1 Score  Recall  Specificity\n",
      "0      IN  RNN_LSTM     0.35      0.75      0.00    0.00         0.86\n",
      "1      MG  RNN_LSTM     0.48      0.50      0.38    0.33         0.65\n",
      "2      PH  RNN_LSTM     0.49      0.28      0.22    1.00         0.20\n",
      "3      SA  RNN_LSTM     0.51      0.64      0.17    0.17         0.77\n",
      "4      TZ  RNN_LSTM     0.38      0.44      0.17    0.33         0.47\n",
      "Les fichiers ont été combinés avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Liste des fichiers à combiner\n",
    "fichiers = [\n",
    "    'Metrics/Combined_ML.csv',\n",
    "    'Metrics/Combined_CNN.csv',\n",
    "    'Metrics/Combined_CNN_LSTM.csv',\n",
    "    'Metrics/Combined_RNN_LSTM.csv'\n",
    "]\n",
    "\n",
    "# Initialiser une liste pour stocker les DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Lire chaque fichier et ajuster les noms de colonnes\n",
    "for fichier in fichiers:\n",
    "    if os.path.exists(fichier):\n",
    "        df = pd.read_csv(fichier)\n",
    "\n",
    "        print(f\"Traitement du fichier : {fichier}\")\n",
    "        print(\"Aperçu des données avant traitement :\")\n",
    "        print(df.head())\n",
    "\n",
    "        # Traitement spécifique pour le fichier Combined_CNN\n",
    "        if 'Metric' in df.columns and 'Value' in df.columns:\n",
    "            # Pivot du DataFrame pour obtenir les métriques en colonnes\n",
    "            df_pivot = df.pivot(index='Country', columns='Metric', values='Value').reset_index()\n",
    "            df_pivot['Best Model'] = 'CNN'  # Ajout d'une colonne pour le modèle\n",
    "            df_pivot.rename(columns={\n",
    "                'AUC-ROC': 'Test AUC',\n",
    "                'Accuracy': 'Test Accuracy',\n",
    "                'F1 Score': 'Test F1 Score',\n",
    "                'Recall': 'Test Sensitivity',\n",
    "                'Specificity': 'Test Specificity'\n",
    "            }, inplace=True)\n",
    "            dataframes.append(df_pivot[['Country', 'Best Model', 'Test Accuracy', 'Test Sensitivity', 'Test Specificity', 'Test F1 Score', 'Test AUC']])\n",
    "        else:\n",
    "            # Renommer les colonnes pour les autres fichiers\n",
    "            df.rename(columns={\n",
    "                'Model': 'Best Model',\n",
    "                'AUC-ROC': 'Test AUC',\n",
    "                'Accuracy': 'Test Accuracy',\n",
    "                'F1 Score': 'Test F1 Score',\n",
    "                'Recall': 'Test Sensitivity',\n",
    "                'Specificity': 'Test Specificity'\n",
    "            }, inplace=True)\n",
    "            dataframes.append(df[['Country', 'Best Model', 'Test Accuracy', 'Test Sensitivity', 'Test Specificity', 'Test F1 Score', 'Test AUC']])\n",
    "\n",
    "        # Vérifier la présence des colonnes avant d'arrondir\n",
    "        metrics_to_round = ['Test Accuracy', 'Test Sensitivity', 'Test Specificity', 'Test F1 Score', 'Test AUC']\n",
    "        existing_metrics = [metric for metric in metrics_to_round if metric in df.columns]\n",
    "\n",
    "        # Arrondir les valeurs des métriques à 2 décimales si elles existent\n",
    "        if existing_metrics:\n",
    "            df[existing_metrics] = df[existing_metrics].fillna(0).round(2)\n",
    "\n",
    "    else:\n",
    "        print(f\"Le fichier {fichier} n'existe pas.\")\n",
    "\n",
    "# Combiner tous les DataFrames en un seul\n",
    "if dataframes:\n",
    "    resultat_combined = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Enregistrer le résultat combiné dans un nouveau fichier CSV\n",
    "    resultat_combined.to_csv('Metrics/Combined_All_Models.csv', index=False)\n",
    "\n",
    "    print(\"Les fichiers ont été combinés avec succès.\")\n",
    "else:\n",
    "    print(\"Aucun fichier trouvé pour la combinaison.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "302d77e4-c0f1-4c76-8e9e-ed5ccf8315a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Best Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Sensitivity</th>\n",
       "      <th>Test Specificity</th>\n",
       "      <th>Test F1 Score</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VN</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PH</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SA</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IN</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UG</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TZ</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MG</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IN</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MG</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PH</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SA</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TZ</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VN</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IN</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MG</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PH</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SA</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TZ</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>UG</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>VN</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country              Best Model  Test Accuracy  Test Sensitivity  \\\n",
       "0       VN    KNeighborsClassifier           0.36              0.08   \n",
       "1       PH  RandomForestClassifier           0.90              0.00   \n",
       "2       SA      LogisticRegression           0.46              0.50   \n",
       "3       IN      LogisticRegression           0.75              0.00   \n",
       "4       UG  RandomForestClassifier           0.66              0.06   \n",
       "5       TZ                     SVC           0.28              0.33   \n",
       "6       MG      LogisticRegression           0.59              0.53   \n",
       "7       IN                     CNN           0.50              1.00   \n",
       "8       MG                     CNN           0.59              0.47   \n",
       "9       PH                     CNN           0.74              0.50   \n",
       "10      SA                     CNN           0.61              0.17   \n",
       "11      TZ                     CNN           0.61              0.67   \n",
       "12      UG                     CNN           0.32              0.56   \n",
       "13      VN                     CNN           0.70              0.31   \n",
       "14      IN                CNN_LSTM           0.88              0.00   \n",
       "15      MG                CNN_LSTM           0.53              0.13   \n",
       "16      PH                CNN_LSTM           0.87              0.00   \n",
       "17      SA                CNN_LSTM           0.71              0.33   \n",
       "18      TZ                CNN_LSTM           0.83              0.00   \n",
       "19      UG                CNN_LSTM           0.55              0.44   \n",
       "20      VN                CNN_LSTM           0.55              0.54   \n",
       "21      IN                RNN_LSTM           0.75              0.00   \n",
       "22      MG                RNN_LSTM           0.50              0.33   \n",
       "23      PH                RNN_LSTM           0.28              1.00   \n",
       "24      SA                RNN_LSTM           0.64              0.17   \n",
       "25      TZ                RNN_LSTM           0.44              0.33   \n",
       "26      UG                RNN_LSTM           0.40              0.31   \n",
       "27      VN                RNN_LSTM           0.70              0.31   \n",
       "\n",
       "    Test Specificity  Test F1 Score  Test AUC  \n",
       "0               0.55           0.09      0.34  \n",
       "1               1.00           0.00      0.73  \n",
       "2               0.45           0.29      0.45  \n",
       "3               0.86           0.00      0.52  \n",
       "4               0.97           0.11      0.46  \n",
       "5               0.27           0.13      0.87  \n",
       "6               0.65           0.55      0.64  \n",
       "7               0.43           0.33      0.78  \n",
       "8               0.71           0.52      0.65  \n",
       "9               0.77           0.29      0.71  \n",
       "10              0.73           0.15      0.28  \n",
       "11              0.60           0.36      0.56  \n",
       "12              0.19           0.36      0.39  \n",
       "13              0.95           0.44      0.72  \n",
       "14              1.00           0.00      0.38  \n",
       "15              0.88           0.21      0.58  \n",
       "16              0.97           0.00      0.34  \n",
       "17              0.82           0.33      0.44  \n",
       "18              1.00           0.00      0.40  \n",
       "19              0.61           0.40      0.53  \n",
       "20              0.55           0.48      0.61  \n",
       "21              0.86           0.00      0.35  \n",
       "22              0.65           0.38      0.48  \n",
       "23              0.20           0.22      0.49  \n",
       "24              0.77           0.17      0.51  \n",
       "25              0.47           0.17      0.38  \n",
       "26              0.45           0.26      0.45  \n",
       "27              0.95           0.44      0.72  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chemin vers le fichier combiné\n",
    "chemin_fichier_combined = 'Metrics/Combined_All_Models.csv'\n",
    "\n",
    "# Lire le fichier CSV\n",
    "df_combined = pd.read_csv(chemin_fichier_combined)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ac1ea6ba-6cac-447b-8088-b8e64c5d003a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les colonnes requises ne sont pas toutes présentes dans le fichier Metrics/Combined_CNN.csv.\n",
      "Les meilleurs modèles ont été extraits avec succès.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Liste des fichiers à combiner\n",
    "fichiers = [\n",
    "    'Metrics/Combined_ML.csv',\n",
    "    'Metrics/Combined_CNN.csv',\n",
    "    'Metrics/Combined_CNN_LSTM.csv',\n",
    "    'Metrics/Combined_RNN_LSTM.csv'\n",
    "]\n",
    "\n",
    "# Initialiser une liste pour stocker les DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Lire chaque fichier et ajuster les noms de colonnes\n",
    "for fichier in fichiers:\n",
    "    if os.path.exists(fichier):\n",
    "        df = pd.read_csv(fichier)\n",
    "\n",
    "        # Renommer les colonnes pour correspondre à la structure souhaitée\n",
    "        df.rename(columns={\n",
    "            'Model': 'Best Model',\n",
    "            'AUC-ROC': 'Test AUC',\n",
    "            'Accuracy': 'Test Accuracy',\n",
    "            'F1 Score': 'Test F1 Score',\n",
    "            'Recall': 'Test Sensitivity',\n",
    "            'Specificity': 'Test Specificity'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # Vérifier que les colonnes nécessaires existent\n",
    "        required_columns = ['Country', 'Best Model', 'Test Accuracy', 'Test Sensitivity', 'Test Specificity', 'Test F1 Score', 'Test AUC']\n",
    "        if all(col in df.columns for col in required_columns):\n",
    "            dataframes.append(df[required_columns])\n",
    "        else:\n",
    "            print(f\"Les colonnes requises ne sont pas toutes présentes dans le fichier {fichier}.\")\n",
    "    else:\n",
    "        print(f\"Le fichier {fichier} n'existe pas.\")\n",
    "\n",
    "# Combiner tous les DataFrames en un seul\n",
    "if dataframes:\n",
    "    resultat_combined = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Garder le modèle avec le AUC le plus élevé pour chaque pays\n",
    "    resultat_final = resultat_combined.loc[resultat_combined.groupby('Country')['Test AUC'].idxmax()]\n",
    "\n",
    "    # Enregistrer le résultat final dans un nouveau fichier CSV\n",
    "    resultat_final.to_csv('Metrics/Best_Model_Per_Country.csv', index=False)\n",
    "\n",
    "    print(\"Les meilleurs modèles ont été extraits avec succès.\")\n",
    "else:\n",
    "    print(\"Aucun fichier trouvé pour la combinaison.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "65a85560-9a9d-4519-89f2-d7102d6620c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Best Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Sensitivity</th>\n",
       "      <th>Test Specificity</th>\n",
       "      <th>Test F1 Score</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IN</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MG</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PH</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SA</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TZ</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UG</td>\n",
       "      <td>CNN_LSTM</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VN</td>\n",
       "      <td>RNN_LSTM</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country              Best Model  Test Accuracy  Test Sensitivity  \\\n",
       "0      IN      LogisticRegression           0.75              0.00   \n",
       "1      MG      LogisticRegression           0.59              0.53   \n",
       "2      PH  RandomForestClassifier           0.90              0.00   \n",
       "3      SA                RNN_LSTM           0.64              0.17   \n",
       "4      TZ                     SVC           0.28              0.33   \n",
       "5      UG                CNN_LSTM           0.55              0.44   \n",
       "6      VN                RNN_LSTM           0.70              0.31   \n",
       "\n",
       "   Test Specificity  Test F1 Score  Test AUC  \n",
       "0              0.86           0.00      0.52  \n",
       "1              0.65           0.55      0.64  \n",
       "2              1.00           0.00      0.73  \n",
       "3              0.77           0.17      0.51  \n",
       "4              0.27           0.13      0.87  \n",
       "5              0.61           0.40      0.53  \n",
       "6              0.95           0.44      0.72  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chemin vers le fichier combiné\n",
    "chemin_fichier_combined = 'Metrics/Best_Model_Per_Country.csv'\n",
    "\n",
    "# Lire le fichier CSV\n",
    "df_combined = pd.read_csv(chemin_fichier_combined)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac5159-6b3f-4454-bd72-9e0e72ef6386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2596105-62bb-46f5-8587-8dc13fd8c589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
